{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2f29e976-cb18-4bcf-ad5e-010b2b1af48c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zoo = {\n",
    "    \"zero123_dtu\": (\n",
    "        91692112, \n",
    "        ['1', '32', '18', '4', '5', '6', '7', '8', '9', '10', '26', '12', '13', '14', '15']),\n",
    "    \"ours_dtu\": (\n",
    "        91650514,\n",
    "        ['16', '32', '63', '49', '50', '36', '22', '38', '54', '25', '71', '72', '73', '44', '45']),\n",
    "    \"zero123_mipnerf360\": (\n",
    "        91688416,\n",
    "        ['15', '9', '3', '18', '5', '34', '35']),\n",
    "    \"ours_mipnerf360\": (\n",
    "        91657828,\n",
    "        ['15', '9', '3', '11', '5', '6', '14']\n",
    "    ),\n",
    "    \"oursanchored_mipnerf360\": (\n",
    "        92764541,\n",
    "        ['1', '9', '3', '11', '5', '6', '14'])\n",
    "}\n",
    "\n",
    "MIPNERF_UID_TO_VIEW_IDX={\n",
    "    'bicycle': 2,\n",
    "    'bonsai': 0,\n",
    "    'counter': 20,\n",
    "    'garden': 0,\n",
    "    'kitchen': 0,\n",
    "    'room': 0,\n",
    "    'stump':11\n",
    "}\n",
    "MIPNERF360_SCENE_UIDS = [\n",
    "    'bicycle',\n",
    "    'bonsai',\n",
    "    'counter',\n",
    "    'garden',\n",
    "    'kitchen',\n",
    "    'room',\n",
    "    'stump',\n",
    "]\n",
    "\n",
    "def _mipnerf360_wid_to_scene(wid):\n",
    "    # gross_hack\n",
    "    return MIPNERF360_SCENE_UIDS[(int(wid) - 1) % 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d1ae8530-bea0-4b51-aa4f-984f72d99098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mediapy\n",
    "import os\n",
    "import glob\n",
    "import einops\n",
    "import numpy as np\n",
    "\n",
    "GCS_PREFIX = \"/gcs/xcloud-shared/kylesargent/zero123_training_runs/\"\n",
    "\n",
    "def gcs_image_accessor(xid, wid, dataset, yield_gt=False):\n",
    "    pattern = os.path.join(GCS_PREFIX, str(xid), str(wid), '*', 'save', '*test.mp4')\n",
    "    [video_path] = glob.glob(pattern)\n",
    "    \n",
    "    video = mediapy.read_video(video_path)\n",
    "    # return video\n",
    "\n",
    "    gt, pred, _, _, _ = einops.rearrange(video, \"t h (five w) three -> five t h w three\", five=5, three=3)\n",
    "    if yield_gt:\n",
    "        to_yield = gt\n",
    "    else:\n",
    "        to_yield = pred\n",
    "    \n",
    "    if dataset == 'mipnerf360':\n",
    "        scene = _mipnerf360_wid_to_scene(wid)\n",
    "        excluded_idx = MIPNERF_UID_TO_VIEW_IDX[scene]\n",
    "    else:\n",
    "        excluded_idx = 25\n",
    "    \n",
    "    for idx, frame in enumerate(to_yield):\n",
    "        if idx != excluded_idx:\n",
    "            yield frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f00eadd4-c57b-44fa-8085-e60dcb2fbcbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pixelnerf_image_accessor(dataset):\n",
    "    if dataset == 'mipnerf360':\n",
    "        path = '/home/jupyter/stylegan3/pixelnerf_datasets/clip_final_eval_out_zeroshot_mipnerf360_withlpips_worldscale.3'\n",
    "    elif dataset == 'dtu':\n",
    "        path = \"/home/jupyter/stylegan3/pixelnerf_datasets/clip_final_eval_out_zeroshot_withlpips_worldscale.5\"\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    image_paths = glob.glob(os.path.join(path, 'dtu_1v', '*', \"*.png\"))\n",
    "    for image_path in image_paths:\n",
    "        yield mediapy.read_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cc8364ac-5161-4a1f-a24e-f51d7bd58af5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero123_dtu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:26<01:45, 26.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ours_dtu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:40<00:57, 19.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero123_mipnerf360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:54<00:33, 16.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ours_mipnerf360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [01:02<00:13, 13.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oursanchored_mipnerf360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:11<00:00, 14.30s/it]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from tqdm import tqdm\n",
    "\n",
    "image_sets = collections.defaultdict(list)\n",
    "\n",
    "for key, (xid, wids) in tqdm(zoo.items()):\n",
    "    print(key)\n",
    "    method, dataset = key.split('_')\n",
    "    \n",
    "    for wid in wids:\n",
    "        image_sets[f\"{method}_{dataset}\"].extend(\n",
    "            list(gcs_image_accessor(xid, wid, dataset)))\n",
    "        \n",
    "    if f\"gt_{dataset}\" not in image_sets:\n",
    "        for wid in wids:\n",
    "            image_sets[f\"gt_{dataset}\"].extend(\n",
    "                list(gcs_image_accessor(xid, wid, dataset, yield_gt=True)))\n",
    "            \n",
    "image_sets[\"pixelnerf_dtu\"].extend(list(pixelnerf_image_accessor(\"dtu\")))\n",
    "image_sets[\"pixelnerf_mipnerf360\"].extend(list(pixelnerf_image_accessor(\"mipnerf360\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "93d0c972-511d-498b-8c50-17b006e29a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('zero123_dtu', (720, 304, 400, 3), 0, 255, dtype('uint8'))\n",
      "('gt_dtu', (720, 304, 400, 3), 0, 255, dtype('uint8'))\n",
      "('ours_dtu', (720, 304, 400, 3), 0, 255, dtype('uint8'))\n",
      "('zero123_mipnerf360', (1413, 256, 256, 3), 0, 255, dtype('uint8'))\n",
      "('gt_mipnerf360', (1413, 256, 256, 3), 0, 255, dtype('uint8'))\n",
      "('ours_mipnerf360', (1413, 256, 256, 3), 0, 255, dtype('uint8'))\n",
      "('oursanchored_mipnerf360', (1413, 256, 256, 3), 0, 255, dtype('uint8'))\n",
      "('pixelnerf_dtu', (720, 300, 400, 3), 18, 247, dtype('uint8'))\n",
      "('pixelnerf_mipnerf360', (1413, 256, 256, 3), 92, 252, dtype('uint8'))\n"
     ]
    }
   ],
   "source": [
    "# validate\n",
    "\n",
    "image_arrs = {k:np.array(v) for (k,v) in image_sets.items()}\n",
    "# print({k:v.shape for (k,v) in image_arrs.items()})\n",
    "_ = [print((k,v.shape, v.min(), v.max(), v.dtype)) for (k,v) in image_arrs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb18ca1-d031-4fae-9c89-0dda3827d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715081e6-7ec9-464e-8e5a-e6e315907f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from metrics import metric_utils\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "\n",
    "DumbOptCls = namedtuple(\"DumbOpt\", [\"device\", \"rank\", \"num_gpus\"])\n",
    "opts = DumbOptCls(device=torch.ones((1,)).cuda().device, rank=0, num_gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdd0a892-334f-48d5-b739-b4c11c826fbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gt_ds = image_arrs['gt_dtu']\n",
    "# pred_ds = image_arrs['zero123_dtu']\n",
    "import importlib\n",
    "\n",
    "def compute_is(gt_ds, pred_ds):\n",
    "    from metrics import inception_score\n",
    "    importlib.reload(inception_score)\n",
    "    from metrics import metric_utils\n",
    "    importlib.reload(metric_utils)\n",
    "\n",
    "    inception_score.metric_utils.compute_feature_stats_for_dataset = (\n",
    "        lambda **kwargs: metric_utils.hijackable_compute_stats(dataset=gt_ds, **kwargs))\n",
    "    inception_score.metric_utils.compute_feature_stats_for_generator = (\n",
    "        lambda **kwargs: metric_utils.hijackable_compute_stats(dataset=pred_ds, **kwargs))\n",
    "    return inception_score.compute_is(\n",
    "        opts, num_gen=len(pred_ds), num_splits=1)\n",
    "    \n",
    "def compute_fid(gt_ds, pred_ds):\n",
    "    from metrics import frechet_inception_distance\n",
    "    importlib.reload(frechet_inception_distance)\n",
    "    from metrics import metric_utils\n",
    "    importlib.reload(metric_utils)\n",
    "\n",
    "    frechet_inception_distance.metric_utils.compute_feature_stats_for_dataset = (\n",
    "        lambda **kwargs: metric_utils.hijackable_compute_stats(dataset=gt_ds, **kwargs))\n",
    "    frechet_inception_distance.metric_utils.compute_feature_stats_for_generator = (\n",
    "        lambda **kwargs: metric_utils.hijackable_compute_stats(dataset=pred_ds, **kwargs))\n",
    "    return frechet_inception_distance.compute_fid(\n",
    "        opts, max_real=len(gt_ds), num_gen=len(pred_ds))\n",
    "    \n",
    "def compute_kid(gt_ds, pred_ds):\n",
    "    from metrics import kernel_inception_distance\n",
    "    importlib.reload(kernel_inception_distance)\n",
    "    from metrics import metric_utils\n",
    "    importlib.reload(metric_utils)\n",
    "\n",
    "    kernel_inception_distance.metric_utils.compute_feature_stats_for_dataset = (\n",
    "        lambda **kwargs: metric_utils.hijackable_compute_stats(dataset=gt_ds, **kwargs))\n",
    "    kernel_inception_distance.metric_utils.compute_feature_stats_for_generator = (\n",
    "        lambda **kwargs: metric_utils.hijackable_compute_stats(dataset=pred_ds, **kwargs))\n",
    "    return kernel_inception_distance.compute_kid(\n",
    "        opts, max_real=len(gt_ds), num_gen=len(pred_ds), num_subsets=100, max_subset_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1dcd2f5-eb6f-4929-938d-3a82302edbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/svl/u/ksarge/miniforge-pypy3/envs/stylegan3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:64: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return default_collate([torch.as_tensor(b) for b in batch])\n",
      "/svl/u/ksarge/miniforge-pypy3/envs/stylegan3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:64: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return default_collate([torch.as_tensor(b) for b in batch])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.5056731859921695e+128"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skimage\n",
    "import numpy as np\n",
    "\n",
    "astronaut = skimage.data.astronaut()\n",
    "\n",
    "ds = np.broadcast_to(astronaut, (100, 512, 512, 3))\n",
    "\n",
    "compute_fid(ds, ds[:, :, ::-1].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8c8de3af-8f0b-439c-9266-f7641c9fd2ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero123_dtu\n",
      "is: (7.758379936218262, 0.0)\n",
      "fid: 93.79453945352734\n",
      "kid: 0.013764171894728526\n",
      "\n",
      "ours_dtu\n",
      "is: (6.810516357421875, 0.0)\n",
      "fid: 79.76314295588246\n",
      "kid: 0.009443904277146486\n",
      "\n",
      "zero123_mipnerf360\n",
      "is: (5.664248943328857, 0.0)\n",
      "fid: 177.69337334933545\n",
      "kid: 0.058030588107638933\n",
      "\n",
      "ours_mipnerf360\n",
      "is: (6.3430304527282715, 0.0)\n",
      "fid: 126.91775902900311\n",
      "kid: 0.03379108493134468\n",
      "\n",
      "oursanchored_mipnerf360\n",
      "is: (6.236597537994385, 0.0)\n",
      "fid: 121.14152737007001\n",
      "kid: 0.031454294369476034\n",
      "\n",
      "pixelnerf_dtu\n",
      "is: (3.734673023223877, 0.0)\n",
      "fid: 329.8599216675181\n",
      "kid: 0.21406792080965908\n",
      "\n",
      "pixelnerf_mipnerf360\n",
      "is: (2.114959955215454, 0.0)\n",
      "fid: 356.10463150517705\n",
      "kid: 0.3136811732559975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in image_sets:\n",
    "    if key.startswith('gt'):\n",
    "        continue\n",
    "    \n",
    "    if key.endswith(\"dtu\"):\n",
    "        gt_ds = image_arrs['gt_dtu']\n",
    "    elif key.endswith(\"mipnerf360\"):\n",
    "        gt_ds = image_arrs['gt_mipnerf360']\n",
    "    \n",
    "    pred_ds = image_arrs[key]\n",
    "    print(key)\n",
    "    print(f\"is: {compute_is(gt_ds, pred_ds)}\")\n",
    "    print(f\"fid: {compute_fid(gt_ds, pred_ds)}\")\n",
    "    print(f\"kid: {compute_kid(gt_ds, pred_ds)}\")\n",
    "    print()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf77c1-79f7-4340-8251-1c29dc9f7f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero123_dtu\n",
    "is: (7.758379936218262, 0.0)\n",
    "fid: 93.79453945352734\n",
    "kid: 0.014226056541982297\n",
    "\n",
    "ours_dtu\n",
    "is: (6.810516357421875, 0.0)\n",
    "fid: 79.76314295588246\n",
    "kid: 0.00963420555160987\n",
    "\n",
    "zero123_mipnerf360\n",
    "is: (5.664248943328857, 0.0)\n",
    "fid: 177.69337334933545\n",
    "kid: 0.0570758872119634\n",
    "\n",
    "ours_mipnerf360\n",
    "is: (6.3430304527282715, 0.0)\n",
    "fid: 126.91775902900311\n",
    "kid: 0.033165712239583305\n",
    "\n",
    "pixelnerf_dtu\n",
    "is: (3.734673023223877, 0.0)\n",
    "fid: 329.8599216675181\n",
    "kid: 0.2145034626736112\n",
    "\n",
    "pixelnerf_mipnerf360\n",
    "is: (2.114959955215454, 0.0)\n",
    "fid: 356.10463150517705\n",
    "kid: 0.3131586584004103"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "stylegan3",
   "name": ".m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m113"
  },
  "kernelspec": {
   "display_name": "stylegan3",
   "language": "python",
   "name": "stylegan3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
